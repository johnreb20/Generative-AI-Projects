# Purpose of this Folder

In this exercise, you'll use Chain Of Thought reasoning to improve LLM's ability to solve reasoning problems. 
Chain of Thought (CoT) reasoning is a technique for teaching LLMs to perform complex reasoning tasks by providing them with examples of how to break down a problem into smaller steps and solve them one by one. This is done by providing the LLM with a few-shot exemplar that outlines the reasoning process. The model is then expected to follow a similar chain of thought when answering the prompt.

CoT reasoning is helpful to LLMs because it allows them to:

- Understand and solve complex problems that would be difficult or impossible to solve with a single step. For example, a CoT-prompted LLM could be used to solve a math word problem by first identifying the relevant information in the problem, then performing the necessary calculations, and finally explaining the solution in a clear and concise way.
- Generate more informative and transparent answers. By providing a step-by-step explanation of their reasoning, CoT-prompted LLMs can help users to understand how they arrived at their answer and to identify any potential errors in their logic. This is especially important for tasks where trust and accountability are critical, such as in healthcare or finance.
- Improve their performance on a variety of reasoning tasks. CoT reasoning has been shown to improve the performance of LLMs on a wide range of tasks, including arithmetic, commonsense reasoning, symbolic reasoning, and code generation.